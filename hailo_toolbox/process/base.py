from abc import ABC, abstractmethod
import numpy as np
from typing import Dict, Any, List, Tuple, Optional, Union
from dataclasses import dataclass, field


@dataclass
class PostprocessConfig:
    """
    Configuration class for postprocessing operations.
    
    This class defines all the parameters needed for various postprocessing tasks
    including detection, segmentation, and keypoint detection.
    """
    # Task type flags
    det: bool = False
    seg: bool = False
    kp: bool = False
    
    # NMS (Non-Maximum Suppression) configuration
    nms: bool = True
    nms_threshold: float = 0.5
    nms_iou_threshold: float = 0.5
    nms_top_k: int = 100
    nms_max_det: int = 100
    nms_score_threshold: float = 0.5
    
    # Detection specific configuration
    det_conf_threshold: float = 0.25
    det_max_detections: int = 300
    det_class_agnostic: bool = False
    
    # Segmentation specific configuration
    seg_conf_threshold: float = 0.25
    seg_mask_threshold: float = 0.5
    seg_max_instances: int = 100
    
    # Keypoint specific configuration
    kp_conf_threshold: float = 0.25
    kp_visibility_threshold: float = 0.5
    kp_max_persons: int = 100
    
    # Input/Output shape configuration
    input_shape: Tuple[int, int] = (640, 640)  # (height, width)
    original_shape: Optional[Tuple[int, int]] = None  # Original image shape
    
    # Model specific configuration
    num_classes: int = 80
    num_keypoints: int = 17  # COCO format
    
    # Additional metadata
    class_names: Optional[List[str]] = None
    keypoint_names: Optional[List[str]] = None
    keypoint_connections: Optional[List[Tuple[int, int]]] = None
    
    def __post_init__(self):
        """Validate configuration parameters after initialization."""
        self._validate_parameters()
        self._set_default_names()
    
    def _validate_parameters(self):
        """Validate all configuration parameters."""
        # Validate confidence thresholds (should be between 0 and 1)
        if not (0.0 <= self.det_conf_threshold <= 1.0):
            raise ValueError(f"det_conf_threshold must be between 0 and 1, got {self.det_conf_threshold}")
        
        if not (0.0 <= self.seg_conf_threshold <= 1.0):
            raise ValueError(f"seg_conf_threshold must be between 0 and 1, got {self.seg_conf_threshold}")
        
        if not (0.0 <= self.kp_conf_threshold <= 1.0):
            raise ValueError(f"kp_conf_threshold must be between 0 and 1, got {self.kp_conf_threshold}")
        
        if not (0.0 <= self.kp_visibility_threshold <= 1.0):
            raise ValueError(f"kp_visibility_threshold must be between 0 and 1, got {self.kp_visibility_threshold}")
        
        if not (0.0 <= self.seg_mask_threshold <= 1.0):
            raise ValueError(f"seg_mask_threshold must be between 0 and 1, got {self.seg_mask_threshold}")
        
        # Validate NMS parameters
        if not (0.0 <= self.nms_iou_threshold <= 1.0):
            raise ValueError(f"nms_iou_threshold must be between 0 and 1, got {self.nms_iou_threshold}")
        
        if not (0.0 <= self.nms_threshold <= 1.0):
            raise ValueError(f"nms_threshold must be between 0 and 1, got {self.nms_threshold}")
        
        if not (0.0 <= self.nms_score_threshold <= 1.0):
            raise ValueError(f"nms_score_threshold must be between 0 and 1, got {self.nms_score_threshold}")
        
        # Validate positive integers
        if self.num_classes <= 0:
            raise ValueError(f"num_classes must be positive, got {self.num_classes}")
        
        if self.num_keypoints <= 0:
            raise ValueError(f"num_keypoints must be positive, got {self.num_keypoints}")
        
        if self.det_max_detections <= 0:
            raise ValueError(f"det_max_detections must be positive, got {self.det_max_detections}")
        
        if self.seg_max_instances <= 0:
            raise ValueError(f"seg_max_instances must be positive, got {self.seg_max_instances}")
        
        if self.kp_max_persons <= 0:
            raise ValueError(f"kp_max_persons must be positive, got {self.kp_max_persons}")
        
        if self.nms_top_k <= 0:
            raise ValueError(f"nms_top_k must be positive, got {self.nms_top_k}")
        
        if self.nms_max_det <= 0:
            raise ValueError(f"nms_max_det must be positive, got {self.nms_max_det}")
        
        # Validate input shape
        if len(self.input_shape) != 2 or any(dim <= 0 for dim in self.input_shape):
            raise ValueError(f"input_shape must be a tuple of two positive integers, got {self.input_shape}")
        
        # Validate original shape if provided
        if self.original_shape is not None:
            if len(self.original_shape) != 2 or any(dim <= 0 for dim in self.original_shape):
                raise ValueError(f"original_shape must be a tuple of two positive integers, got {self.original_shape}")
    
    def _set_default_names(self):
        """Set default class and keypoint names if not provided."""
        if self.class_names is None:
            self.class_names = [f"class_{i}" for i in range(self.num_classes)]
        elif len(self.class_names) != self.num_classes:
            raise ValueError(f"Length of class_names ({len(self.class_names)}) must match num_classes ({self.num_classes})")
        
        if self.keypoint_names is None:
            # Default COCO keypoint names for 17 keypoints
            if self.num_keypoints == 17:
                self.keypoint_names = [
                    "nose", "left_eye", "right_eye", "left_ear", "right_ear",
                    "left_shoulder", "right_shoulder", "left_elbow", "right_elbow",
                    "left_wrist", "right_wrist", "left_hip", "right_hip",
                    "left_knee", "right_knee", "left_ankle", "right_ankle"
                ]
            else:
                self.keypoint_names = [f"keypoint_{i}" for i in range(self.num_keypoints)]
        elif len(self.keypoint_names) != self.num_keypoints:
            raise ValueError(f"Length of keypoint_names ({len(self.keypoint_names)}) must match num_keypoints ({self.num_keypoints})")


@dataclass
class DetectionResult:
    """
    Result structure for object detection.
    """
    boxes: np.ndarray  # Shape: (N, 4) - [x1, y1, x2, y2]
    scores: np.ndarray  # Shape: (N,) - confidence scores
    class_ids: np.ndarray  # Shape: (N,) - class indices
    masks: Optional[np.ndarray] = None  # Shape: (N, H, W) - instance masks
    
    def __len__(self) -> int:
        return len(self.boxes)


@dataclass
class SegmentationResult:
    """
    Result structure for segmentation.
    """
    masks: np.ndarray  # Shape: (N, H, W) or (H, W) for semantic segmentation
    scores: Optional[np.ndarray] = None  # Shape: (N,) - confidence scores
    class_ids: Optional[np.ndarray] = None  # Shape: (N,) - class indices
    boxes: Optional[np.ndarray] = None  # Shape: (N, 4) - bounding boxes
    
    def __len__(self) -> int:
        return len(self.masks) if len(self.masks.shape) == 3 else 1


@dataclass
class KeypointResult:
    """
    Result structure for keypoint detection.
    """
    keypoints: np.ndarray  # Shape: (N, K, 3) - [x, y, visibility]
    scores: np.ndarray  # Shape: (N,) - person confidence scores
    boxes: Optional[np.ndarray] = None  # Shape: (N, 4) - person bounding boxes
    
    def __len__(self) -> int:
        return len(self.keypoints)


class BasePreprocessor(ABC):
    """
    Abstract base class for all preprocessors.
    
    Preprocessors are responsible for preparing input data for model inference.
    """
    
    @abstractmethod
    def preprocess(self, data: Any) -> Dict[str, np.ndarray]:
        """
        Preprocess input data for model inference.
        
        Args:
            data: Input data to preprocess
            
        Returns:
            Dictionary mapping input names to preprocessed arrays
        """
        pass


class BasePostprocessor(ABC):
    """
    Abstract base class for all postprocessors.
    
    Postprocessors are responsible for converting raw model outputs
    into structured, usable results.
    """
    
    def __init__(self, config: Optional[PostprocessConfig] = None):
        """
        Initialize the postprocessor with configuration.
        
        Args:
            config: Postprocessing configuration
        """
        self.config = config or PostprocessConfig()
    
    @abstractmethod
    def postprocess(self, 
                   raw_outputs: Dict[str, np.ndarray], 
                   original_shape: Optional[Tuple[int, int]] = None) -> Any:
        """
        Postprocess raw model outputs into structured results.
        
        Args:
            raw_outputs: Dictionary of raw model outputs
            original_shape: Original image shape (height, width) for coordinate scaling
            
        Returns:
            Structured postprocessing results
        """
        pass
    
    def __call__(self, 
                 raw_outputs: Dict[str, np.ndarray], 
                 original_shape: Optional[Tuple[int, int]] = None) -> Any:
        """
        Callable interface for postprocessing.
        
        Args:
            raw_outputs: Dictionary of raw model outputs
            original_shape: Original image shape for coordinate scaling
            
        Returns:
            Structured postprocessing results
        """
        return self.postprocess(raw_outputs, original_shape)


def non_max_suppression(boxes: np.ndarray, 
                       scores: np.ndarray, 
                       iou_threshold: float = 0.5,
                       score_threshold: float = 0.5,
                       max_detections: int = 100) -> np.ndarray:
    """
    Apply Non-Maximum Suppression to remove overlapping bounding boxes.
    
    Args:
        boxes: Array of bounding boxes with shape (N, 4) in format [x1, y1, x2, y2]
        scores: Array of confidence scores with shape (N,)
        iou_threshold: IoU threshold for suppression
        score_threshold: Minimum score threshold
        max_detections: Maximum number of detections to keep
        
    Returns:
        Array of indices of boxes to keep
    """
    # Filter by score threshold
    valid_indices = scores >= score_threshold
    if not np.any(valid_indices):
        return np.array([], dtype=np.int32)
    
    boxes = boxes[valid_indices]
    scores = scores[valid_indices]
    original_indices = np.where(valid_indices)[0]
    
    # Sort by scores in descending order
    sorted_indices = np.argsort(scores)[::-1]
    
    # Calculate areas
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    
    keep = []
    while len(sorted_indices) > 0 and len(keep) < max_detections:
        # Pick the box with highest score
        current = sorted_indices[0]
        keep.append(current)
        
        if len(sorted_indices) == 1:
            break
            
        # Calculate IoU with remaining boxes
        remaining = sorted_indices[1:]
        
        # Calculate intersection coordinates
        x1 = np.maximum(boxes[current, 0], boxes[remaining, 0])
        y1 = np.maximum(boxes[current, 1], boxes[remaining, 1])
        x2 = np.minimum(boxes[current, 2], boxes[remaining, 2])
        y2 = np.minimum(boxes[current, 3], boxes[remaining, 3])
        
        # Calculate intersection area
        intersection = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)
        
        # Calculate union area
        union = areas[current] + areas[remaining] - intersection
        
        # Calculate IoU
        iou = intersection / (union + 1e-6)
        
        # Keep boxes with IoU below threshold
        sorted_indices = remaining[iou <= iou_threshold]
    
    return original_indices[keep]


def scale_boxes(boxes: np.ndarray, 
               original_shape: Tuple[int, int], 
               input_shape: Tuple[int, int]) -> np.ndarray:
    """
    Scale bounding boxes from input image size to original image size.
    
    Args:
        boxes: Bounding boxes with shape (N, 4) in format [x1, y1, x2, y2]
        original_shape: Original image shape (height, width)
        input_shape: Input image shape (height, width)
        
    Returns:
        Scaled bounding boxes
    """
    if boxes.size == 0:
        return boxes
    
    # Calculate scaling factors
    scale_y = original_shape[0] / input_shape[0]
    scale_x = original_shape[1] / input_shape[1]
    
    # Scale coordinates
    scaled_boxes = boxes.copy()
    scaled_boxes[:, [0, 2]] *= scale_x  # x coordinates
    scaled_boxes[:, [1, 3]] *= scale_y  # y coordinates
    
    return scaled_boxes


def scale_keypoints(keypoints: np.ndarray, 
                   original_shape: Tuple[int, int], 
                   input_shape: Tuple[int, int]) -> np.ndarray:
    """
    Scale keypoints from input image size to original image size.
    
    Args:
        keypoints: Keypoints with shape (N, K, 3) where last dim is [x, y, visibility]
        original_shape: Original image shape (height, width)
        input_shape: Input image shape (height, width)
        
    Returns:
        Scaled keypoints
    """
    if keypoints.size == 0:
        return keypoints
    
    # Calculate scaling factors
    scale_y = original_shape[0] / input_shape[0]
    scale_x = original_shape[1] / input_shape[1]
    
    # Scale coordinates
    scaled_keypoints = keypoints.copy()
    scaled_keypoints[:, :, 0] *= scale_x  # x coordinates
    scaled_keypoints[:, :, 1] *= scale_y  # y coordinates
    # Keep visibility unchanged
    
    return scaled_keypoints
